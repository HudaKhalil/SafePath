{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2eb1d9-3e86-44cc-b495-72c21c50c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- London Police UK cleaner (reads directly from the folder) ---\n",
    "import os, glob, math\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05be2d1f-6680-415c-be00-d634a278036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) POINT THIS TO FOLDER ===\n",
    "# Use a raw string (r\"...\") so backslashes are handled correctly on Windows\n",
    "BASE_DIR = r\"C:\\Users\\hksai\\OneDrive\\Documents\\Group_Porject_Doc\\Data_Police_UK_ALL(2025)\\2025-08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6d6754-e9e5-4d40-b991-930e3f364b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) OUTPUT FILES (will be written in the current working directory) ===\n",
    "OUT_CLEAN = \"london_crime_clean.csv\"\n",
    "OUT_BAD = \"rows_excluded.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4faa45e-5603-4885-8c63-eb99b682ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3) CLEANING CONFIG ===\n",
    "FORCE_FILTERS = [\"metropolitan\", \"city-of-london\"]\n",
    "BBOX = {\"lat_min\": 51.28, \"lat_max\": 51.70, \"lon_min\": -0.51, \"lon_max\": 0.33}\n",
    "CHUNKSIZE = 200_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f71554-c23f-4df5-ad58-7e2ef3d5c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_MAP = {\n",
    "    \"violence and sexual offences\": \"Violence_Sexual\",\n",
    "    \"anti-social behaviour\": \"Antisocial_Behavior\",\n",
    "    \"vehicle crime\": \"Vehicle_Crime\",\n",
    "    \"bicycle theft\": \"Theft_Bicycle\",\n",
    "    \"theft from the person\": \"Theft_Personal\",\n",
    "    \"shoplifting\": \"Theft_Retail\",\n",
    "    \"other theft\": \"Theft_Other\",\n",
    "    \"criminal damage and arson\": \"Criminal_Damage\",\n",
    "    \"public order\": \"Public_Order\",\n",
    "    \"drugs\": \"Drug_Offenses\",\n",
    "    \"burglary\": \"Burglary\",\n",
    "    \"robbery\": \"Robbery\",\n",
    "    \"possession of weapons\": \"Weapons\",\n",
    "    \"other crime\": \"Other\"\n",
    "}\n",
    "\n",
    "SEVERITY = {\n",
    "    \"Violence_Sexual\": 3.0, \"Robbery\": 2.8, \"Burglary\": 2.5, \"Vehicle_Crime\": 2.0,\n",
    "    \"Theft_Bicycle\": 1.8, \"Criminal_Damage\": 1.5, \"Public_Order\": 1.3,\n",
    "    \"Drug_Offenses\": 1.2, \"Antisocial_Behavior\": 1.0, \"Theft_Other\": 1.0,\n",
    "    \"Theft_Personal\": 1.5, \"Theft_Retail\": 0.8, \"Weapons\": 2.6, \"Other\": 1.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9e52ea7-e9ac-480c-97b2-93585b4a70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4) HELPERS ===\n",
    "def standardize_columns(df):\n",
    "    return df.rename(columns={c: c.strip().replace(\" \", \"_\").lower() for c in df.columns})\n",
    "\n",
    "def within_bbox(lat, lon):\n",
    "    return ((lat >= BBOX[\"lat_min\"]) & (lat <= BBOX[\"lat_max\"]) &\n",
    "            (lon >= BBOX[\"lon_min\"]) & (lon <= BBOX[\"lon_max\"]))\n",
    "\n",
    "def filter_forces(df):\n",
    "    # Keep rows where either 'reported_by' or 'falls_within' mention the target forces\n",
    "    cols = [c for c in (\"reported_by\",\"falls_within\") if c in df.columns]\n",
    "    if not cols:\n",
    "        return df, pd.DataFrame()\n",
    "    mask = df[cols[0]].str.lower().str.contains(\"|\".join(FORCE_FILTERS), na=False)\n",
    "    if len(cols) > 1:\n",
    "        mask |= df[cols[1]].str.lower().str.contains(\"|\".join(FORCE_FILTERS), na=False)\n",
    "    return df[mask], df[~mask]\n",
    "    \n",
    "    # 5) FIND CSVs UNDER YOUR FOLDER\n",
    "csv_files = sorted(glob.glob(os.path.join(BASE_DIR, \"**\", \"*.csv\"), recursive=True))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found under: {BASE_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78e1c3c1-27a8-4c4b-9466-bc4c13f342db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) MAIN CLEANING LOOP (chunked)\n",
    "seen = set()\n",
    "good_chunks, bad_chunks = [], []\n",
    "total_in, total_kept = 0, 0\n",
    "\n",
    "for fp in csv_files:\n",
    "    for chunk in pd.read_csv(fp, chunksize=CHUNKSIZE):\n",
    "        total_in += len(chunk)\n",
    "        chunk = standardize_columns(chunk)\n",
    "\n",
    "        # Types\n",
    "        if \"latitude\" in chunk.columns:\n",
    "            chunk[\"latitude\"] = pd.to_numeric(chunk[\"latitude\"], errors=\"coerce\")\n",
    "        if \"longitude\" in chunk.columns:\n",
    "            chunk[\"longitude\"] = pd.to_numeric(chunk[\"longitude\"], errors=\"coerce\")\n",
    "        if \"month\" in chunk.columns:\n",
    "            chunk[\"month_dt\"] = pd.to_datetime(chunk[\"month\"].astype(str) + \"-01\", errors=\"coerce\")\n",
    "\n",
    "            # London forces only\n",
    "        chunk, not_force = filter_forces(chunk)\n",
    "        if len(not_force):\n",
    "            nf = not_force.copy()\n",
    "            nf[\"bad_reason\"] = \"not_london_force\"\n",
    "            bad_chunks.append(nf)\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "             # Fill missing\n",
    "        if \"last_outcome_category\" in chunk.columns:\n",
    "            chunk[\"last_outcome_category\"] = chunk[\"last_outcome_category\"].fillna(\"Outcome Pending\")\n",
    "        if \"location\" in chunk.columns:\n",
    "            chunk[\"location\"] = chunk[\"location\"].fillna(\"Location Withheld\")\n",
    "        if \"lsoa_code\" in chunk.columns:\n",
    "            chunk[\"lsoa_code\"] = chunk[\"lsoa_code\"].fillna(\"Unknown LSOA\")\n",
    "\n",
    "        # Categories & weights\n",
    "        if \"crime_type\" in chunk.columns:\n",
    "            chunk[\"crime_category\"] = (\n",
    "                chunk[\"crime_type\"].astype(str).str.strip().str.lower().map(CATEGORY_MAP).fillna(\"Other\")\n",
    "            )\n",
    "        else:\n",
    "            chunk[\"crime_category\"] = \"Other\"\n",
    "        chunk[\"severity_weight\"] = chunk[\"crime_category\"].map(SEVERITY).fillna(1.0)\n",
    "\n",
    "        # Season & temporal weight\n",
    "        if \"month_dt\" in chunk.columns:\n",
    "            month_num = chunk[\"month_dt\"].dt.month\n",
    "            season_map = {12:\"Winter\",1:\"Winter\",2:\"Winter\",3:\"Spring\",4:\"Spring\",5:\"Spring\",\n",
    "                          6:\"Summer\",7:\"Summer\",8:\"Summer\",9:\"Autumn\",10:\"Autumn\",11:\"Autumn\"}\n",
    "            chunk[\"season\"] = month_num.map(season_map)\n",
    "            ref = pd.to_datetime(\"today\").normalize()\n",
    "            delta = (ref - chunk[\"month_dt\"]).dt.days.clip(lower=0)\n",
    "            lam = math.log(2)/180.0\n",
    "            chunk[\"temporal_weight\"] = (-lam*delta).apply(math.exp)\n",
    "        else:\n",
    "            chunk[\"season\"] = None\n",
    "            chunk[\"temporal_weight\"] = 1.0\n",
    "\n",
    "        # Dedup\n",
    "        for c in (\"crime_id\",\"month\",\"latitude\",\"longitude\",\"crime_type\"):\n",
    "            if c not in chunk.columns:\n",
    "                chunk[c] = None\n",
    "        keys = (\n",
    "            chunk[\"crime_id\"].fillna(\"\") + \"|\" +\n",
    "            chunk[\"month\"].fillna(\"\") + \"|\" +\n",
    "            chunk[\"latitude\"].round(6).astype(str) + \"|\" +\n",
    "            chunk[\"longitude\"].round(6).astype(str) + \"|\" +\n",
    "            chunk[\"crime_type\"].fillna(\"\")\n",
    "        ).tolist()\n",
    "        dup_mask = []\n",
    "        for k in keys:\n",
    "            if k in seen:\n",
    "                dup_mask.append(True)\n",
    "            else:\n",
    "                seen.add(k); dup_mask.append(False)\n",
    "        dup_mask = pd.Series(dup_mask, index=chunk.index)\n",
    "\n",
    "        dups = chunk[dup_mask].copy()\n",
    "        if len(dups):\n",
    "            dups[\"bad_reason\"] = \"duplicate\"\n",
    "            bad_chunks.append(dups)\n",
    "\n",
    "        chunk = chunk[~dup_mask]\n",
    "        total_kept += len(chunk)\n",
    "        good_chunks.append(chunk)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "076f61c2-650d-4598-85d6-1f8186537038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete!\n",
      "  Source folder : C:\\Users\\hksai\\OneDrive\\Documents\\Group_Porject_Doc\\Data_Police_UK_ALL(2025)\\2025-08\n",
      "  CSV files read: 41\n",
      "  Rows in       : 516837\n",
      "  Rows kept     : 87594\n",
      "→ Clean data    : C:\\Users\\hksai\\london_crime_clean.csv\n",
      "→ Excluded rows : C:\\Users\\hksai\\rows_excluded.csv\n"
     ]
    }
   ],
   "source": [
    "# 7) SAVE OUTPUTS\n",
    "if good_chunks:\n",
    "    pd.concat(good_chunks, ignore_index=True).to_csv(OUT_CLEAN, index=False)\n",
    "if bad_chunks:\n",
    "    pd.concat(bad_chunks, ignore_index=True, sort=False).to_csv(OUT_BAD, index=False)\n",
    "\n",
    "print(\"Cleaning complete!\")\n",
    "print(f\"  Source folder : {BASE_DIR}\")\n",
    "print(f\"  CSV files read: {len(csv_files)}\")\n",
    "print(f\"  Rows in       : {total_in}\")\n",
    "print(f\"  Rows kept     : {total_kept}\")\n",
    "print(f\"→ Clean data    : {Path(OUT_CLEAN).resolve()}\")\n",
    "print(f\"→ Excluded rows : {Path(OUT_BAD).resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b157e-224b-4f17-bdb8-fe96a89e38b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
